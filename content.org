:CONFIG:
#+hugo_base_dir: ./
#+hugo_section: ./
#+hugo_weight: auto
#+hugo_autoset_lastmod: t

#+seq_todo: TODO DRAFT DONE
#+options: creator:t
#+property: header-args :eval never-export
:END:

#+title: walkergriggs.com source file
#+author: Walker Griggs
#+email: walkergriggs.com

* Pages
** About
:PROPERTIES:
:export_hugo_section: pages
:export_file_name: about
:END:

#+begin_center
*Hi, my name is Walker Griggs, and I reboot your servers.*
#+end_center

I'm an infrastructure and software engineer working at [[https://heroku.com][Heroku]], living in San Francisco, and focusing on public cloud technologies and distributed systems.

My educational background is in Computer Science and English, and I'm passionate about the hidden technologies that silently transform our day to day. Outside of the office, I enjoy puzzling, riding my bike, writing occasionally, and playing far too much chess.

Aside from being my personal website, this site hosts my thoughts -- young, old, ill-informed, and carefully considered. Every word on this site is generated from an Emacs Org file, renered by Hugo, and hosted on Github.

Of course, the opinions here are my own, not of my employer.

* Posts                                                               
:PROPERTIES:
:export_hugo_section: posts
:END:
** TODO Five Years with Emacs                                         :emacs:
:PROPERTIES:
:export_file_name: five-years-with-emacs
:export_date: 2020-12-28
:END:
** A Year with Emacs                                                  :emacs:
:PROPERTIES:
:export_file_name: a-year-with-emacs
:export_date: 2017-01-05
:END:

_It is important to preface that everything in this article is opinion and based off (roughly) a year of heavy Emacs usage. It is also important to know that this article will be updated along side my configuration and tastes. So without further ado..._

We all know Emacs is an immensely powerful beast. We also know how easy it is to venture down a rabbit hole of elisp and never surface. I liken it to a carpenter replacing a door. After removing the old door, he notices the hinges are askew. He removes the hinges only to notice rot in the door frame. By the time he replaces the frame, he notices a slight difference in shade between the new frame and old moldings... The learning curve for Emacs is wonderfully circular. That being said, I would like to take a moment and explain my configuration in moderate detail.

Before I get too technical, I should probably explain my fascination and reservation with Emacs. Brief background: I was forced into using Emacs when the only other editor on the lab machines was Gedit (and Vi, but we'll forget about that for now). In all honestly, it was quite a hassle. I began compiling a minimal init.el out of necessity. Linum, flyspell, you name it. It was certainly a gradual transition from cushy Atom, but, after a long while, it became an addiction. It wasn't until I discovered a keyboard designed with Emacs in mind (Atreus) did I see Emacs (and the devoted community) in all of its glory.

As for my reservations...

#+begin_quote
The learning curve is far too steep. My time is best spent elsewhere.
#+end_quote

WRONG. The weeks of struggling with Meta keys and Emacs pinkie pays off. Trust me. My workflow has increased substantially, and I feel extraordinarily comfortable in my configuration. Granted, emacs is truly a lifestyle. Embrace it.

#+begin_quote
It's a bloated editor packed with legacy functionality. The startup time is just too long!
#+end_quote

MYTH. You think Emacs is too heavy for you system? Try running Eclipse and Chrome simultaneously and then get back to me. As long as your config file is optimized (cough cough 'use-package'), the startup time won't be longer than a couple of seconds. Granted, on a system with limited resources, Vi may be a better option. Which brings me to my biggest qualm. Vi is an editor. Emacs is an editor AND IDE. When remoting into a server, I'm not about to Xforward a fully functional Emacs when bandwidth and memory are scarce. For that reason, I keep a modest .vimrc on hand for some quick cli editing.

**** Configuration
***** melpa and use-package

Melpa is a very common package manager for Emacs. I try not to rely on it, though it certainly comes in handy. The simple (and recommended) solution...

#+begin_src lisp
;; Melpa
(require 'package)
(setq package-enable-at-startup nil)
(add-to-list 'package-archives
  '("melpa" . "https://melpa.org/packages/"))
(add-to-list 'package-archives
  '("melpa-stable" . "http://stable.melpa.org/packages/"))
#+end_src

Now it wasn't until a friend picked through my config when I learned about 'use-package'. UP is a wonderful macro written by John Wiegley that declares and isolates packages in your config. Each package can then be initialized, configured, and bound independently. This is a must use...

#+begin_src lisp
;; Bootstrap 'use-package'
(unless (package-installed-p 'use-package)
    (package-refresh-contents)
    (package-install 'use-package))
(setq use-package-verbose t)
#+end_src

***** tabs / whitespace

The next few go hand in hand: tabs and whitespace. I'd like to reiterate, these are simply opinions. Feel free to disagree, but I cannot stand tabs in my code. Tab size varies across environments but a space will ALWAYS be one column. Case closed. That being said, tab functionality is quite nice, so I've turned indent-tabs-mode to nil. Simply...

#+begin_src lisp
(setq-default indent-tabs-mode nil)
(setq-default tab-width 2)
#+end_src

The next is an acquired taste: whitespace-mode. Ever since I properly configured my whitespace (invisibles) to be tastefully visible, I've grown to appreciate the subtly clean code. Trailing whitespace / unnecessary new lines have since disappeared.

#+begin_src lisp
;; Whitespace
(use-package whitespace
    :bind (("C-c C-w" . whitespace-mode))
    :init
    (dolist (hook '(prog-mode-hook text-mode-hook conf-mode-hook))
        (add-hook hook #'whitespace-mode))
    :config
    (add-hook 'prog-mode-hook 'whitespace-mode)
    (global-whitespace-mode t) ;; Whitespace ON.
    (setq whitespace-global-modes '(not org-mode))
    (setq whitespace-line-column 80) ;; Set indent limit.
    (setq whitespace-display-mappings
    '(
        (space-mark 32 [183] [46])
        (newline-mark 10 [172 10])
        (tab-mark 9 [9655 9] [92 9]))))
#+end_src

Here, I've remapped the display for the space, newline, and tab to suit my taste. Whitespace is shown on pretty much every mode except org (where it really is never needed). Other than that, lines over 80 columns are highlighted. Simple and lovely.

***** helm

Helm is a package that I never knew I needed, until I started using it. It's described as an incremental completion and selection narrowing framework. Essentially, it gives me proper control over buffers, files, and commands similar to Smex (with a Neotree feel). Helm, however, is capably of out of order regex matching which is surprisingly uncommon.

Here, I've remapped the helm key bindings to reflect standard C-x C-f / tab-complete functionality.

#+begin_src lisp
;; Helm
(use-package helm
    :ensure t
    :bind
    (("M-x" . helm-M-x)
    ("C-x C-f" . helm-find-files))
    :config
    (setq helm-split-window-in-side-p        t  ;; opens helm inside window
          helm-move-to-line-cycle-in-source  t
          helm-autoresize-min-height         20
          helm-autoresize-max-height         40
          helm-scroll-amount                 8)
    (define-key helm-map (kbd "<tab>") 'helm-execute-persistent-action)
    (define-key helm-map (kbd "C-z") 'helm-select-action)
    (setq helm-mode-fuzzy-match t))
#+end_src

***** org

Org-mode might be one of the most expansive and powerful features of emacs. It is perfect for daily organization, notes, etc. Recently, I've adopted the org-clock, which can time tasks and generate useful reports. I may not be a freelancer who charges by the hour, but it certainly keeps me on track and focused.

#+begin_src lisp
;; Org
(use-package org
    :ensure t
    :mode (("\\.org$" . org-mode))
    :bind (("C-c C-x C-i" . org-clock-in)
           ("C-c C-x C-o" . org-clock-out)
           ("C-c C-x C-j" . org-clock-goto)
           ("C-c C-x C-r" . org-clock-report))
    :config
    (progn
        (define-key org-mode-map "\M-q" 'toggle-truncate-lines)
        (setq org-directory "~/org")
        (setq org-clock-persist t)
        (setq org-clock-mode-line-total 'current)))
#+end_src

While these snippets are not my configuration in it's entirety, the full file is not a hulking mass. It can be found at in my [[https://github.com/WalkerGriggs/DotFiles/blob/master/.emacs][dotfiles repo]]. Feel free to take and modify what you need. If you have anything to contribute, feel free to shoot me an em
** TODO Generically correct
    :PROPERTIES:
    :export_file_name: generically_correct
    :export_date: 2021-11-07
    :END:

    It's easy to be generically correct.

    To say "docker is sweepingthe industry and changing how we deploy to production" is technically correct. In fact, any statement without sufficient detail or evidence can be correct. These statements are hardly useful, though.

    Falling into this generically accurate twilight zone is eays. I know I'm guilty of reverting to vague handwavingin the absense of fact.

    The question becomes: are these statements worth writing or speaking in the first place. As with anything, context is important. If you're using these statements to pad your writing, fill air, or reach some work limit they're objectively useless. General statements are not convincing filler either -- you're likely better off acknowledging the holes in your arugment than introducing possible attack vectors. 
** TODO Coding Diddles                                             :learning:
:PROPERTIES:
:export_file_name: coding_diddles
:export_date: 2021-12-20
:END:

#+BEGIN_QUOTE
There is a time in every manâ€™s education when he arrives at the conviction that envy is ignorance; that imitation is suicide; that he must take himself for better, for worse, as his portion; that though the wide universe is full of good, no kernel of nourishing corn can come to him but through his toil bestowed on that plot of ground which is given to him to till. -- Ralph Waldo Emerson
#+END_QUOTE

I'm guilty of a development cycle (as I'm sure many of you are as well) where I 1) stumble upon a new idea 2) excitedly put pen to paper 3) resurface after a few hours of development to check "has this been attempted before". Naturally, it has. At this point I'm faced with the decision to scrap every and mark it down as a fun investigation, or to forge ahead knowing with the nagging thought that someone beat me to the punch.

Of course, this isn't a productive outlook but for some inate reason is a shared human experience.

A collegue of mine picked up woodcarving recently. They told me about their battle with the "originality demon" and how, even when learning a new and right brain skill, they felt ever knifestroke needed to be an original one. Each complete whittle needed to an attrative addition to a catalogue of novel works. Naturally, learning from videos or books is difficult when the idea of copying cut after cut challenges your ego.

They took pause, though, when an instructor referred to some of the more simple, instructive carvings as a "diddle". Diddles are by nature common, practiced, and rehersed. There's nothing original about a diddle, and so my colleague took solice in the idea that regardless of profession and skill level, we need to iterate on the trite before we can produce a modicom of original work.

Programming is no different.

Sorting algorithms, data structures, security groups, emnist data, hello worlds -- all are diddles. There's nothing original about heap sort and certainly classifying hand written letter is a solved problem.

We should take solice in that. Before we write our magnus opal, we should understand existing systems. How can we presume to be entirely original until we know /all/ prior art. Given the glut of public repos on Github alone, it's hard to imagine anyone can onboard that knowledge.

There's another perspective too, that novel systems are just the amalgamation of diddles. Before Etcd could promise distributed concensus, they had to implement Raft. Nearly all Hashicorp products use their own flavor of logging and Michelle's own CLI framework.

So practice your diddles. Re-implement your darlings, and study how "innovations" make use of your favorite data structures. Steal patterns, borrow optimizaitons

** TODO State Machines All the Way Down
:PROPERTIES:
:export_file_name: state-machines-all-the-way-down
:export_date: 2020-06-06
:END:

** TODO Digital Homesteading                                       :learning:
    :PROPERTIES:
    :export_file_name: digital-homesteading
    :export_date: 2021-12-08
    :END:

Tech is [[https://trends.google.com/trends/explore?cat=5&date=2011-01-01%202021-01-01&q=%2Fm%2F011spz0k,%2Fg%2F11b7lxp79d,%2Fm%2F0wkcjgj][changing]]. Whether you want to call it horitzontal scaling, scaling out, distributing, or deconstructing; the ways we structure, write, test, and deploy systems is changing.

I argue though, that the ways we learn, however, are not changing but should be. Learning the latest, individual abstraction isn't enough anymore. Side projects are often too narrow and our exposure to "enterprise systems" is limited. We, as engineers, are not adequately tailoring our "studies" to fit the needs of industry... but we could be.

I propose a form of continuous learning called "digital homesteading" which emphasizes composition and encourages self-sufficiency.

**** Homesteading, generally

Homesteading is synonymous with the Homestead Act of 1862 which granted US citizens a western tract of 160 acres should they be willing to settle and farm the land. Generally, the US governemnt used homesteading to incentive western expansion, but we'll ignore the political machinations. Fast forward to the 1970, the Back to the Land Movement worked to similar effect, where people took up rural smallholdings in search of increased autonomy and self-sufficiency.

Homesteading, in this context, is analogous to self-sufficiency. More often than not, homesteaders were physically seperated from society or relied on a small, local community. They grew their own crops, hunted their own game, built their own shelters, and mended their own fences. If their roof leaked, they patched it. If their clothes tore, they patched them just the same. The list goes on, but in every example, they had to rely on their own intuition and experience to solve their daily problems. If they didn't have experience with a particular trade, they were pretty well incentivised to learn.

**** Continuous learning, generally

As is common in ever-changing industries, engineers need to constantly onboard new material, practice our craft, and mind our information diet. Most importantly, we need to learn in ways which compliment idustry needs.

Speaking to my own experience, my typical "learning lifecycle" is fairly sequential and well deliniated. I'll think up a project which suits the some topic. If I'm feeling ambitious, I might even blend two new topics; a language and paradigm, for example. From there, I'll start reading documentation, lay the groundwork, and mould the core behaviors. More often than not though, that project ends up on the private-repo pile after a few iterations or I feel sufficiently versed on the topic. I forget about it, and move on to the next topic.

I'd be willing to bet this pattern is pretty common. This method isn't "bad" or ineffectual, but there are some areas for improvement.

First, like cramming for a test, we don't retain a lot of that info. I'm especially guilty of searching through old projects for a pattern or practice I found useful, but couldn't reproduce.

Perhaps more importatnly, these projects also exist in a vacuum. We understand the bounds of the topic in isolation, but don't always see the interaction between two systems. Think of this like unit testing vs integration testing; one isolates behaviors and mocks the bounderies, the other encapulates behavior and instead focuses on interacton.

See again: "we need to learn in ways which compliment industry needs".

**** Homesteading meets continuous learning

So far we've touched on homesteading and continuous learning in practice. Let's bridge that gap by first reviewing examples of what I consider to be digital homesteading in practice, and then using those examples to derrive a few characteristics of digital homsteading in theory.

The most approachable example is a homelab (note the shared root: "home"). An average homelab might be a few rasberry pis as "compute nodes", an old laptop repurposed as a NAS, or maybe a desktop as a router. You, as the "homesteader", might run KVM or ESXI (type 1 hypervisors) on a makeshift server. You might run Telegraf, InfluxDB, and Grafana to collect, store, and visualize hardware metrics. You might also setup a home network with Pfsense and stream movies with Plex. Slowly, you're building out an ecosystem of systems and services.

Another example. Say you're in the market for a new graphics card, but are having trouble following the various stock trackers, raffles, and notifications. You might write a web app that lets you define alerts through a simple domain specific language. Of course, your friends on discord or slack or IRC want to use that app too. Everyone loves a good chatbot and there are lots of off the shelf solutions, but maybe you want to write your own. You'll want to understand the bots failure modes, so you setup Rollbar or Sentry to error tracking. Maybe you'll even want to push soft touch alerts to your home, so you write a Philip Hue integration. The possibilities are endless.

In both examples,
- We're building an ecosystem. We're layering services or systems which interact with and complement eachother.
- Our services persistent, but not production.
- The individual components span multiple layers.
- Each service provides useful but not vital functionality
- We're self sufficient along at least one vertical.

***** Ecosystem
We're not just considering how an individual component behaves, but how multiple systems interact. Enterprise servces are transitioning to horizontal systems of scale, and we need to factor that into our design process.

Consider your digital homestead. Where is the barn in relation to the fields? The food cellar? Have we considered how the three systems work in concert? With regards to our more tangible example: have we considered how our discord bot pulls information from the web app? Are they tighly coupled? Does the webapp implement any business logic, or just expose the DSL? Do the latest stock alerts need to be persisted, or only cached?

***** Persistent

Digital homesteads should run around the clock. According to the 2020 Stack Overflow Survey, DevOps and Site Reliability Engineers are value multipliers in enterprise environments.

#+BEGIN_QUOTE
Site reliability engineers and DevOps specialists remain among the highest paid individual contributor roles. 80% of respondents believe that DevOps is at least somewhat important, and 44% work at organizations with at least one dedicated DevOps employee.
#+END_QUOTE

Persistent homesteads go beyond SRE though. When we take responsibility for supporting every stage of software development -- when we're product owners responding to feature requests, senior leadership driving priority, on-call operators triaging downed systems, SRE debuggig service blips, and DevOps implementing resilient runtime environments -- we're service owners.

Service ownership is overlooked in the majority of continuous learning projects, despite it being such a critical facet of successful enterprise services.


***** Span multiple layers
It's important to think about where and how things are run. This diversity adds perspective

***** Useful but not vital
This bullet ties back to the "persistent but not production" mantra. You're only going to resent your digital homestead if you rely on it for "business critical" tasks. These systems will be flawed, they will take time, they will break, and you will need to fix them.

Hosting an SMTP server for your professional email or writing a React clone for an enterprise service is objectively a bad idea. In the end of the day, we're not looking to reinvent the wheel, but to instead understand why the wheel is fabulous, how the wheel is fallable, and how the wheel can be leveraged to great success.

If we give our homestead value, we'll stay invested. If we rely on our homestead to feed the neighborhood, we risk a famine.

***** Self-sufficient
In self-sufficiency, we find the most valuable lessons. If something isn't readily available, we can write it ourselves. If we aren't immediately sure how to write it ourselves, we can learn through trial and error.

Of course you could follow this rule to an extreme -- I'm not suggesting we write our own compilers (though you certainly could challenge yourself). I'm suggesting that in an industry of higher order abstarctions, we might consider our own Back to the Land Movement.

** TODO A Standard for Password Management
:PROPERTIES:
:export_file_name: standard-for-password-management
:export_date: 2021-12-06
:END:
**** tldr;
Passwords are inherently insecure. We've layered a number of secure practices (some consumer facing, others system facnig) like MFA, security questions, oauth, and OIDC to complimen passwords and have built supporting systems like password managers to enable users to reliably and safely use sufficiently secure passwords, but we haven't written a standard for password management.

I propose a standard set of endpoints which let users, or password managers by proxy, programatically manage their passwords.

Use case: Say a user has 100 accounts at 100 different websites. Some, but not all support MFA. The user wants to rotate their passwords semi-regularly. Currently, they have to visit each of the 100 websites, login, navigate through unique account settings,  manually update their password, and update their password manager.

Instead, a user should be able to press one button in their password manager which will programatically generate a new password and update the account settings through the proposed endpoints. Better yet, the password manager should do this automatically every N days without the user needing to trigger the process.

** Learning Go Generics with Advent of Code                              :go:
    :PROPERTIES:
    :export_file_name: learning_go_generics_with_aoc
    :export_date: 2021-12-15
:END:

/This post is a living draft and may be revised. If you have any comments, questions, or concerns, please reach out./

Yesterday, the Go core team released [[https://go.dev/blog/go1.18beta1][go1.18beta1]] which formally introduces generics. There isn't a whole lot of info circulating yet aside from git history and [[https://groups.google.com/g/golang-nuts][go-nuts]] experiments, but the overall reception feels very positive.

Personally, I've been hands on with generics for the better part of a week all thanks to the [[https://adventofcode.com][Advent of Code]], which has been the perfect venue to take generics for a spin. If you're not familiar with AOC...

#+BEGIN_QUOTE
Advent of Code is an advent calendar of small programming puzzles for a variety of skill sets and skill levels that can be solved in any programming language you like. People use them as a speed contest, interview prep, company training, university coursework, practice problems, or to challenge each other.

You don't need a computer science background to participate - just a little programming knowledge and some problem solving skills will get you pretty far. Nor do you need a fancy computer; every problem has a solution that completes in at most 15 seconds on ten-year-old hardware. -- [[http://was.tl/][Eric Wastl]]
#+END_QUOTE

This article will cover the basics of generics (or enough to get you started) and uses my AOC experiments a case study.

**** Generics, generally

Go feels immediately more flexible with generics. The language is less prescriptive but still opinionated, and the implementation feels wonderfully idiomatic. But what do I mean by that?

For starters, generics feel very low-touch from a developers point of view. They've only added three new features:

- Type parameters for functions and types
- Type sets defined by interfaces
- Type inference

***** Type parameters

Type parameters are one or more name-type parings that look visually similar to our standard parameters; the only difference being type params are surrounded by square brackets, not parentheses. The square brackets, thankfully, are a consistent syntax you'll see used in struct declarations and variable initialization.

#+BEGIN_SRC go
[a, b constraint1, c constraint2]
#+END_SRC

Consider the ~Max~ function you've written dozens of times. We can now replace our strongly typed numeric like ~int32~ or ~float64~ with a far more permissible type parameter ~T~. ~T~, in this instance, is any type which fulfills the ~Ordered~ constraint (which we'll circle back to constraints shortly).

#+BEGIN_SRC go
func Max[T constraints.Ordered](x, y T) T {
    if x > y {
        return x
    }
    return y
}
#+END_SRC

When we call this function, we have to explicitly pass the type argument as part of the functions instantiation. Instatiation is a two part process where the compiler...

1. substitutes the type argument for all instances of the respective type parameter. In our case, the two ~T~ arguments and one return value are swapped to be ~int~ specifically.
2. checks that the two function arguments implement the constraints. The compiler will fail to instantiate if this step fails. Again, in our case, the compiler checks that 3 and 4 satisfy the ~Ordered~ constraint.

#+BEGIN_SRC go
max := Max[int](3,4)
#+END_SRC

It's also worth pointing our that the function call above both instantiates and runs the function. We could instantiate the function separately, which might be a slight optimisation in some cases.

#+BEGIN_SRC go
maxInt := Max[int]

max := maxInt(3,4)
#+END_SRC

As for data structures, these type parameters work the same way. Types can optionally have a type parameter list, and methods of that type must declare matching type lists in the receiver.

#+BEGIN_SRC go
type Grid[T any] struct {
    values        []T
    height, width int
}

func (g *Grid[T]) At(x, y int) T {
    return g.Values[(g.height * y) + x]
}

var grid Grid[int]
#+END_SRC

Notice the ~any~ keyword? It's now an alias for ~interface{}~!

***** Type sets and constraints

So what are these "constraints" we've been tossing around?

Constraints are a new package in the standard library that describe type sets. Type sets are just lists of types which satisfy some target behavior. For example, the ~Signed~ constraint is the set of all signed integer types, and the ~Integer~ constraint is the union of ~Signed~ and ~Unsigned~. To check if a type satisfies a constraint, the compiler just checks if that type is an element in the constraint's type set.

At the time of writing this, there are only six, simple constraints: ~Signed~, ~Unsigned~, ~Integer~, ~Float~, ~Complex~, and ~Ordered~. ~Ordered~ is the most permissive and includes all floats, integers, and strings; and was the constraint I reached for most often in initial testing.

#+BEGIN_SRC go
// Signed is a constraint that permits any signed integer type.
// If future releases of Go add new predeclared signed integer types,
// this constraint will be modified to include them.
type Signed interface {
        ~int | ~int8 | ~int16 | ~int32 | ~int64
}

// Integer is a constraint that permits any integer type.
// If future releases of Go add new predeclared integer types,
// this constraint will be modified to include them.
type Integer interface {
        Signed | Unsigned
}
#+END_SRC

You may have also noticed that these constraints are actually interfaces under the hood. Traditionally, interfaces have defined a 'method set' and every type which implements those methods implements that interface.

The other perspective, and one which is more relevant to generics, is that interfaces describe a set of /types/ and the method set is only a means by which we filter the set of /all types/ -- the empty interface. It seems only reasonable then that we should be able add a specific type to that list directly.

Well, as of ~1.18beta1~, interfaces /can/ enumerate types directly by way of a type set (~Signed | Unsigned~, for example). Of course, method sets as we have known then are still 100% compatible and preferred in many cases.

In summary, type constraints are just interfaces and the types which satisfy those constraints are those enumerated by the interface. When you're defining a generic function with a constraint, you're basically defining a big list of all possible argument types.

For now, this flavor of type set interfaces can only be used as function constraints, but in the future I would like to see variables loosely typed according to a given constraint.

**** Advent of Code

Day 9 or "Smoke Basin" is a fun exercise in navigating grids which boils down to "can you find elements in a grid in which all surrounding 'neighbors' are larger than it". Before we dive into the puzzle logic, lets setup our data structures.

Fortunately, grids are common data structures in the Advent of Code, but unfortunately one that I've rewritten a number of times depending on the element type. My preferred approach is to structure the grid as a list and to define several helper methods to access elements with X,Y coordinates.

We'll need to directly compare Grid elements but would like this to be reused for, say, ASCII characters in the future, so the ~Ordered~ constraint makes the most sense.

#+BEGIN_SRC go
type Point struct {
        X, Y int
}

type Grid[T constraints.Ordered] struct {
        H, W int
        Vals []T
}
#+END_SRC

As for the helper methods, notice how the function receivers also specify the generic type ~T~? That tells the compiler that these methods are applicable to any Grid which meets its constraint. A receiver like ~(g *Grid[int])~ would only be applicable to integer grids. Otherwise these are standard helper methods to access generic values in the grid, either by point coordinates, index, or relative direction.

#+BEGIN_SRC go
// Index returns the integer index value for a grid element given some point.
func (g *Grid[T]) Index(p *Point) int {
        return (p.Y * g.W) + p.X
}

// Point returns the a point object for a grid element given some index.
func (g *Grid[T]) Point(i int) *Point {
        return &Point{
                X: i % g.W,
                Y: i / g.W,
        }
}

// At returns the element found at some given point.
func (g *Grid[T]) At(p *Point) T {
        return g.Vals[g.Index(p)]
}

// InBounds returns true if the point is within the grid, and false if not.
func (g *Grid[T]) InBounds(p *Point) bool {
        return p.X >= 0 && p.X < g.W &&
                p.Y >= 0 && p.Y < g.H
}

// Neighbors returns a list of point objects for each (in-bound) element of the
// grid, given a list of directions. For example, the direction (1,0) would be
// the point to the right.
func (g *Grid[T]) Neighbors(p *Point, directions []*Point) (points []*Point) {
        for _, direction := range directions {
                tmp := p.Add(direction)
                if g.InBounds(tmp) {
                        points = append(points, tmp)
                }
        }
        return
}
#+END_SRC

Finally, the puzzle logic.

The puzzle input for day 9 was a grid of integers where each point represented the depth of the sea floor with 0 being the lowest and 9 being the highest. The first part of the puzzle is to find all of the low points (a point where the neighboring values are all greater) and add their values.

A simple solution is to iterate over the grid, check if each point is a "low point", and add the low point's values to a running total. There are a number of optimizations we could make here, but lets stick with the direct approach first.

#+BEGIN_SRC go
// IsLowPoint returns true if the given Point is lower than all its neighbors,
// and false if not.
func IsLowPoint[T constraints.Ordered](grid Grid[T], target *Point) bool {
        for _, p := range grid.Neighbors(point, FOUR_AXIS_DIRECTIONS) {
                if grid.At(p) <= grid.At(target) {
                        return false
                }
        }
        return true
}

// LowPoints returns a list of Points which correspond to all the low points in
// some given grid.
func LowPoints[T constraints.Ordered](grid Grid[T]) (points []*Point) {
        for i := range grid.Vals {
                point := grid.Point(i)
                if IsLowPoint(grid, point) {
                        points = append(points, point)
                }
        }
        return
}

// PartOne returns the sum of the values of all the low points in some given
// grid.
func PartOne(grid Grid[int]) (sum int) {
        for _, point := range LowPoints(grid) {
                sum += grid.At(point) + 1
        }
        return
}
#+END_SRC

A few things to note. In ~PartOne~, we're actually specifying that our generic grid is a grid of integers. Although the addition operator is technically defined on strings for concatenation, the compiler knows that the return value must be an integer and the ~Ordered~ type set includes strings and floats. So to guarantee type safely, the compiler will enforce a strongly typed grid. The ~LowPoints~ and ~IsLowPoint~ functions only ever perform comparisons on grid values, so those can stay generic.

Part two is an iteration on the Grid we've just written, so I'll leave that as an exercise for you.

**** Final thoughts

Up until ~1.18beta1~, I was frequently copying and pasting data structures and helper methods. In the best case, that led to code duplication. In the worst case, that led to unnecessary extraction and  abstraction. Generics feel like a handy way to inject flexibility into your code without resorting to re-use or adapter patterns, for example. That said, I'll have to see sufficiently complex implementations to form any lasting opinions.

At this point, I worry that -- like any new, shiny tool -- developers will look to cram generics wherever they can. Frankly, I think that generics will make the biggest impact in standard libraries -- not your application backend. The most obvious example is ~math~, where currently /every/ function takes a ~float64~ and requires a significant amount of casting if you're working with integers (~int(math.Abs(float64(value)))~).

As for AOC, I'm all for using [[https://pkg.go.dev/container/heap][container/heap]] to implement a priority queue once in a while, but rewriting methods like ~Abs~, ~Max~, and ~Min~ is slow and inefficient. Even the standard 2-dimensional grid gets repetitive after a while. As a result, puzzlers have written their own [[https://github.com/Bogdanp/awesome-advent-of-code#go][libraries of helper methods]] to speed things along; contents range from simple data structures to stdin readers tailored to AOCs input.

I tried writing a library myself last year, but it felt brittle. Grids wont always contain integers and I should be able to compare strings just as easy as numerics. Interfaces might have been an option, but felt clumsy for my use case.

Enter: generics. I'm taking another stab with the help of ~1.18beta1~ -- all contributions are welcome.

** ZNC, the right way                                                   :irc:
    :PROPERTIES:
    :export_file_name: znc_the_right_way
    :export_date: 2021-10-13
    :END:

    I've setup [[https://wiki.znc.in/ZNC][ZNC]] one too many times.

    Sometimes I forget it's [[https://en.wikipedia.org/wiki/Riding_shotgun][riding shotgun]] on a spare droplet heading to the trash heap. Other times, my payment method expires and so too does the instance. Other times I'm too lazy to host it in the cloud at all, so I run it locally. In any case, today I wanted to set up ZNC the right way... for the last time.

    I also want to document the process for posterity and stop scouring the web for the same articles time after time.

    The TODO list for today:
    - Setup a dedicated domain
    - Provision a dedicated droplet, hosted on [[https://www.digitalocean.com/][DigitalOcean]]
    - Configure separate listeners for IRC and HTTP traffic
    - Generate an SSL cert with [[https://letsencrypt.org/][LetsEncrypt]]
    - Setup [[https://nginx.org/en/][Nginx]] to terminate SSL traffic and proxy to ZNC

**** Dedicated domain and droplet

     I'll gloss over the relatively simple steps like [[https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04][provisioning a droplet]], [[https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-20-04][securing the firewall]], [[https://wiki.znc.in/Installation][installing ZNC]], and [[https://www.digitalocean.com/community/tutorials/how-to-point-to-digitalocean-nameservers-from-common-domain-registrars][purchasing a domain]].

     tldr; I...

     1. Provisioned a droplet.
     2. Purchased a new domain. I opted for a ~.chat~ TLD because I thought it was appropriate
     3. Directed the registrar to DigitalOcean's nameservers. Consolidating behind a single control panel makes life much easier.
     4. Created an A record with an ~irc~ subdomain pointing at the IP of my new droplet.

     For the remainder of this post, I'll use ~irc.example.chat~ as my placeholder domain!
    
**** Configuring ZNC
     How you configure ZNC is a matter of personal taste. I opt to load fairly standard modules like [[https://wiki.znc.in/Chansaver][chanserver]], [[https://wiki.znc.in/Fail2ban][fail2ban]], [[https://wiki.znc.in/Log][log]], and [[https://wiki.znc.in/Identfile][identfile]] but feel free to go crazy! One thing that is important to mention though, are the separate listeners.

     I created one listener for SSL IRC traffic over 6697 and one listener for non-SSL HTTP traffic over 8080. The web listener has SSL disabled because 1) it's only a self signed cert 2) it's only hosting to ~localhost~.
     
     #+BEGIN_SRC xml
       <Listener listener0>
           AllowIRC = true
           AllowWeb = false
           IPv4 = true
           IPv6 = false
           Port = 6697
           SSL = true
           URIPrefix = /
       </Listener>

       <Listener listener1>
           AllowIRC = false
           AllowWeb = true
           Host = localhost
           IPv4 = true
           IPv6 = false
           Port = 8080
           SSL = false
           URIPrefix = /
       </Listener>
     #+END_SRC
     
**** Configuring Nginx
     I'll first preface this section by saying: I'm not an Nginx wizard by any means. In fact, most of this configuration comes from the [[https://www.nginx.com/blog/using-free-ssltls-certificates-from-lets-encrypt-with-nginx/][Nginx blog]] and [[https://stackoverflow.com/questions/34236949/znc-on-a-subdomain-with-nginx-reverse-proxy][Stack Overflow]].

     Before we can generate a certificate, we want to add a basic configuration. I dropped a file in ~/etc/nginx/config.d~ and create a softlink to ~sites-available~ and ~sites-enabled~.

     #+BEGIN_SRC bash
       touch /etc/nging/config.d/irc.example.chat
       ln -s /etc/nginx/config.d/irc.example.chat /etc/nginx/sites-available
       ln -s /etc/nginx/config.d/irc.example.chat /etc/nginx/sites-enabled
     #+END_SRC

     I then edited the parent configuration. Fortunately, it's fairly readable; nginx will proxy all SSL traffic from ~irc.example.chat~ to our ZNC localhost listener. We can also set a few headers in the process.

     #+BEGIN_SRC text
         server {
             listen      443 ssl http2;
             server_name irc.example.chat;
             access_log  /var/log/nginx/irc.log combined;

             location / {
                 proxy_pass http://127.0.0.1:8080;
                 proxy_set_header      Host             $host;
                 proxy_set_header      X-Real-IP        $remote_addr;
                 proxy_set_header      X-Forwarded-For  $proxy_add_x_forwarded_for;
                 proxy_set_header      X-Client-Verify  SUCCESS;
                 proxy_set_header      X-Client-DN      $ssl_client_s_dn;
                 proxy_set_header      X-SSL-Subject    $ssl_client_s_dn;
                 proxy_set_header      X-SSL-Issuer     $ssl_client_i_dn;
                 proxy_read_timeout    1800;
                 proxy_connect_timeout 1800;
             }
         }
     #+END_SRC

The ~ssl_certificate~ configs will be added by ~certbot~ in the next step. If they aren't added for whatever reason, they should look something like...

     #+BEGIN_SRC text
       ssl_certificate     /etc/letsencrypt/live/irc.example.chat/fullchain.pem;
       ssl_certificate_key /etc/letsencrypt/live/irc.example.chat/privkey.pem;
     #+END_SRC
     
**** Generating certs with LetsEncrypt

     Now the fun part, and the reason to setup the domain in the first place. I used the [[https://www.eff.org/][EFF's]] handy [[https://certbot.eff.org/][certbot]] with Nginx drivers to provision a cert with LetsEncrypt. Technically the Nginx drivers aren't necessary -- you could provision the certs directly -- but the added config editor is a nice feature.

     ~certbot~ took care of just about everything!

     #+BEGIN_SRC bash
       sudo apt-get install certbot python3-certbot-nginx

       certbot --nginx -d irc.example.chat
     #+END_SRC

     I say "just about" because these certs still expire every 90 days. I'm guaranteed to forget about the cert, so I set a cron job (~sudo crontab -e~) to renew the cert every week.
     
     #+BEGIN_SRC text
       0 0 * * 0 certbox renew --quiet
     #+END_SRC

**** Configuring Weechat
     The last step of any ZNC install is to setup your client. I use [[https://weechat.org/][Weechat]], so the next steps may be different for you.

     Weechat needs to validate ZNC's SSL cert to connect over ~6697~, so grab the SSL certificate fingerprint from the droplet first.
     
    #+BEGIN_SRC bash
      cat ~/.znc/znc.pem \
          | openssl x509 -sha512 -fingerprint -noout \
          | tr -d ':' \
          | tr 'A-Z' 'a-z' \
          | cut -d = -f 2
    #+END_SRC

    On the weechat client, I added the ~ZNC~ server with a default network, set the fingerprint, connected, and saved my changes. One detail that I forget constantly: these creds aren't your network creds, they're your ZNC creds.
     
    #+BEGIN_SRC text
      /server add ZNC irc.example.chat/6697 -ssl -username=username/network -password=password
      /set irc.server.ZNC.ssl_fingerprint <fingerprint>
      /connect ZNC
      /save
    #+END_SRC

    Most networks require you to authenticate with SASL these days, which I set through Weechat. Another option is to load the SASL module and set your credentials through the web console.
    
    #+BEGIN_SRC text
      /msg *Status LoadMod sasl
      /msg *SASL Set nick pass
      /msg *SASL RequireAuth true
    #+END_SRC

    And that's about it. We've setup the A record for our domain, configured separate HTTP and IRC listeners for ZNC, generated an SSL cert through LetsEncrypt, proxied web traffic to ZNC with Nginx, and connected securely with Weechat. A pretty productive afternoon!

    If you'd like to chat, you can find me on [[https://libera.chat/][libera.chat]]!

** Ergodox Infinity LCD Firmware                                  :keyboards:
:PROPERTIES:
:export_file_name: ergodox-infinity-lcd-firmware
:export_date: 2017-03-21
:END:

So you've got yourself an Ergodox Infinity. Congratulations! Everyone probably thinks your a little bit crazy spending that much on a keyboard that strange with LCD displays that small and a layout you're struggling to type on. But it's ok -- anyone who shares this strange obsession probably understands.

This post is really to demonstrate how to change the default layer's LCD logo. [[http://asciipr0n.net/ergodox-infinity-logo/][Asciipr0n]] has a very clean guide to this, but I find that parts of it are (if not the majority of it is) out of date. Since the firmware has been updated, I thought I'd update the guide.

**** Prerequisites

I don't want to go too deep into these. Essentially, here is the shopping list of the things you'll need...

***** Firmware

The firmware, and really the whole reason for this post, well be using is the [[https://github.com/kiibohd/controller][kiibohd/controller]]. Jacob Alexander (aka Haata) is not only Input Clubs head honcho, but he IS Input Club (well... sorta). He not only wrote kiibohd, but also wrote kll (the keyboard layout language). You'll want to clone his firmware...

***** dfu-util

This toolchain is what we'll be using to flash our firmware onto the board. I downloaded mine from apt-get but it's also available on Homebrew. It's simple enough to download.

***** gcc-arm-none-eabi

This one may only apply to me, but I feel like it shouldn't go unsaid. I needed to download the gcc-arm-none-eabi package to properly build the arm firmware with the gcc compiler. Granted, I'm running Debian over here, so you OSX users may not need this step.

***** Python Imaging Library

This is only necessary if you plan to use kiibohd's bitmap2Struct.py conversion file. Custom logos can only be flashed in the form of byte array, so this script it highly recommended... unless you want to write your byte array by hand. Download 'Image' with pip...

**** Customize Layout

So now that we have everything we need to continue, customize your layout. I just use [[https://configurator.input.club/][Input Club's Configurator]]. It's quite simple and doesn't require too much explanation. Just select the button you want to change, and choose its new function. Go as deep into the layering as you wish. My one recommendation: keep a FLASH button on each half in layer seven. This way, you wont have to flip over your board and hit the reset button with paperclip.

Once you have everything mapped out, download the firmware from the configurator and set aside the ZIP file for later.

If you have aversion to this configurator, so be it. You can use whatever program --or lack thereof if you hate yourself -- you want, as long as the .kll files compile in the end

**** Create a Logo

This part is fun and quite straight forward. Create a logo that fits inside 128x32 screen. Anything large won't get flashed. You can create a the logo in any way, as long as you can get it to .bmp file. Originally, I used [[http://www.piskelapp.com/][Piskel]] to create mine.

#+attr_html: :width 50%
[[file:static/ergodox-infinity-lcd-firmware/game_of_life.png]]

I created the permutation of a glider from Conway's Game of Life. If you don't know exactly what that is, I highly recommend looking into it.

Essentially, the bitmap can be whatever so long as it's a black foreground on white background. (Though... I've just begun to tinker with and observe the conversion of color bitmaps to the monochromatic lcd display... So you can always give that a try).

Now in order to flash this new logo onto your board, it needs to be in the form of a byte array. The easiest way to convert your bitmap into the byte array is to use the firmware's [[https://github.com/kiibohd/controller/blob/master/Scan/STLcd/bitmap2Struct.py][bitmap2Struct.py]] -- as I mentioned earlier. This script spits out two visual representations of the bitmap and the byte array. Just shove the output into a file for later.

#+begin_src bash
python bitmap2Struct.py --filename <filename> > ByteArray.txt
#+end_src

Here is what my ByteArray.txt file look like:

#+begin_src
uint8_t array[] = {
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0xf0, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x0f, 0x00, 0x00, 0x00, 0x00,
}
#+end_src

**** Prepare the Firmware

Now that we have all of our files ready to go, it's time to prep the firmware. A few things have changed in the structure of the firmware, so it does take a few steps to get setup. Oddly enough, we need to build the default ergodox firmware in order to rebuild ours later.

#+begin_src bash
cd controller/Keyboards
./ergodox.bash
#+end_src

Now you may notice in the firmware's root directory, a 'kll' directory has been created. That is where we need to add our custom layouts. So make yourself a layout directory and copy in all our .kll files from the ZIP the configurator created.

#+begin_src bash
mkdir controller/kll/layouts/<my_layout>
cp <configurator ZIP>/*.kll controller/kll/layouts/<my_layout>
#+end_src

Since we have our logo's byte array all squared away, all we have to do is include it. Head into the Scan directory and copy the infinity_ergodox module.

#+begin_src bash
cd controller/Scan
cp -r Infinity_Ergodox Infinity_Ergodox_Custom
#+end_src

Now the one and only thing we need to alter in here is the STLcdDefaultImage in scancode_map.kll. Replace the default Input Club's byte array with our custom byte array from earlier.

Bingo. Now our layouts are almost ready to be flashed. We now need to quickly modify our own build script.

#+begin_src bash
cd controller/Keyboards && cp ergodox.bash ergodox-custom.bash
#+end_src

Edit this new bash file and update the DefaultMap and PartialMaps to include each layer's .kll map created in the configurator. You can also alter the BuildPath, but I'm not building more than one set of firmware at a time, so I leave them as the default ICED-L and ICED-R. Do note: each map (default or partial) requires the lcdFuncMap. Here is mine for example:

#+begin_src bash
# This is the default layer of the keyboard
# NOTE: To combine kll files into a single layout, separate them by spaces
# e.g.  DefaultMap="mylayout mylayoutmod"
DefaultMap="<my_layout>/MDErgo1-Default-0 lcdFuncMap"

# This is where you set the additional layers
# NOTE: Indexing starts at 1
# NOTE: Each new layer is another array entry
PartialMaps[1]="<my_layout>/MDErgo1-Default-1 lcdFuncMap"
PartialMaps[2]="<my_layout>/MDErgo1-Default-2 lcdFuncMap"
PartialMaps[3]="lcdFuncMap"
PartialMaps[4]="lcdFuncMap"
PartialMaps[5]="lcdFuncMap"
PartialMaps[6]="lcdFuncMap"
PartialMaps[7]="<my_layout>/MDErgo1-Default-7 lcdFuncMap"
#+end_src

Finally, change the ScanModule from Infinity_Ergodox to Infinity_Ergodox_Custom or whatever you called your Scan Module. Now we should be all ready to flash.

**** Build and Flash

Now that we have everything set and ready to go, we can actually get this firmware onto your board and have you on your way. First step, rebuild the default firmware from earlier, but run your custom build script this time.

#+begin_src bash
cd controller/Keyboards
./ergodox-custom.bash
#+end_src

This should build your new firmware and create two directories: ICED-L.gcc and ICED-R.gcc. Those contain the binary files to flash.

#+begin_src bash
# Connect only your left board and enter flash mode
sudo dfu-util --download ICED-L.gcc/kiibohd.dfu.bin

# Connect only your right board and enter flash mode
sudo dfu-util --download ICED-R.gcc/kiibohd.dfu.bin
#+end_src

At this point, your Ergodox Infinity should be both flash with your layout and your custom logo. Happy hacking!
